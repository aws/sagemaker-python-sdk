{
    "model_id": "meta-textgeneration-llama-2-7b-f",
    "provider": "meta",
    "url": "https://ai.meta.com/resources/models-and-libraries/llama-downloads/",
    "version": "4.19.0",
    "min_sdk_version": "2.225.0",
    "training_supported": true,
    "incremental_training_supported": true,
    "hosting_ecr_specs": {
        "framework": "huggingface-llm",
        "framework_version": "2.0.0",
        "py_version": "py310"
    },
    "hosting_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference/v1.1.0/",
    "hosting_script_key": "source-directory-tarballs/meta/inference/textgeneration/v1.2.3/sourcedir.tar.gz",
    "hosting_prepacked_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference-prepack/v1.1.0/",
    "hosting_prepacked_artifact_version": "1.1.0",
    "hosting_use_script_uri": false,
    "hosting_eula_key": "fmhMetadata/eula/llamaEula.txt",
    "inference_vulnerable": false,
    "inference_dependencies": [],
    "inference_vulnerabilities": [],
    "training_vulnerable": false,
    "training_dependencies": [
        "accelerate==0.33.0",
        "bitsandbytes==0.39.1",
        "black==23.7.0",
        "brotli==1.0.9",
        "datasets==2.14.1",
        "docstring-parser==0.16",
        "fire==0.5.0",
        "huggingface-hub==0.24.2",
        "inflate64==0.3.1",
        "loralib==0.1.1",
        "multivolumefile==0.2.3",
        "mypy-extensions==1.0.0",
        "nvidia-cublas-cu12==12.1.3.1",
        "nvidia-cuda-cupti-cu12==12.1.105",
        "nvidia-cuda-nvrtc-cu12==12.1.105",
        "nvidia-cuda-runtime-cu12==12.1.105",
        "nvidia-cudnn-cu12==8.9.2.26",
        "nvidia-cufft-cu12==11.0.2.54",
        "nvidia-curand-cu12==10.3.2.106",
        "nvidia-cusolver-cu12==11.4.5.107",
        "nvidia-cusolver-cu12==11.4.5.107",
        "nvidia-cusparse-cu12==12.1.0.106",
        "nvidia-nccl-cu12==2.19.3",
        "nvidia-nvjitlink-cu12==12.3.101",
        "nvidia-nvtx-cu12==12.1.105",
        "pathspec==0.11.1",
        "peft==0.4.0",
        "py7zr==0.20.5",
        "pybcj==1.0.1",
        "pycryptodomex==3.18.0",
        "pyppmd==1.0.0",
        "pyzstd==0.15.9",
        "safetensors==0.4.2",
        "sagemaker_jumpstart_huggingface_script_utilities==1.2.7",
        "sagemaker_jumpstart_script_utilities==1.1.9",
        "scipy==1.11.1",
        "shtab==1.7.1",
        "termcolor==2.3.0",
        "texttable==1.6.7",
        "tokenize-rt==5.1.0",
        "tokenizers==0.19.1",
        "torch==2.2.0",
        "transformers==4.43.1",
        "triton==2.2.0",
        "trl==0.8.1",
        "typing-extensions==4.8.0",
        "tyro==0.7.3"
    ],
    "training_vulnerabilities": [],
    "deprecated": false,
    "hyperparameters": [
        {
            "name": "int8_quantization",
            "type": "text",
            "default": "False",
            "options": [
                "True",
                "False"
            ],
            "scope": "algorithm"
        },
        {
            "name": "enable_fsdp",
            "type": "text",
            "default": "True",
            "options": [
                "True",
                "False"
            ],
            "scope": "algorithm"
        },
        {
            "name": "epoch",
            "type": "int",
            "default": 1,
            "min": 1,
            "max": 1000,
            "scope": "algorithm"
        },
        {
            "name": "learning_rate",
            "type": "float",
            "default": 0.0001,
            "min": 1e-08,
            "max": 1,
            "scope": "algorithm"
        },
        {
            "name": "lora_r",
            "type": "int",
            "default": 8,
            "min": 1,
            "scope": "algorithm"
        },
        {
            "name": "lora_alpha",
            "type": "int",
            "default": 32,
            "min": 1,
            "scope": "algorithm"
        },
        {
            "name": "target_modules",
            "type": "text",
            "default": "q_proj,v_proj",
            "scope": "algorithm"
        },
        {
            "name": "lora_dropout",
            "type": "float",
            "default": 0.05,
            "min": 0,
            "max": 1,
            "scope": "algorithm"
        },
        {
            "name": "instruction_tuned",
            "type": "text",
            "default": "False",
            "options": [
                "True",
                "False"
            ],
            "scope": "algorithm"
        },
        {
            "name": "chat_dataset",
            "type": "text",
            "default": "True",
            "options": [
                "True",
                "False"
            ],
            "scope": "algorithm"
        },
        {
            "name": "add_input_output_demarcation_key",
            "type": "text",
            "default": "True",
            "options": [
                "True",
                "False"
            ],
            "scope": "algorithm"
        },
        {
            "name": "per_device_train_batch_size",
            "type": "int",
            "default": 1,
            "min": 1,
            "max": 1000,
            "scope": "algorithm"
        },
        {
            "name": "per_device_eval_batch_size",
            "type": "int",
            "default": 1,
            "min": 1,
            "max": 1000,
            "scope": "algorithm"
        },
        {
            "name": "max_train_samples",
            "type": "int",
            "default": -1,
            "min": -1,
            "scope": "algorithm"
        },
        {
            "name": "max_val_samples",
            "type": "int",
            "default": -1,
            "min": -1,
            "scope": "algorithm"
        },
        {
            "name": "seed",
            "type": "int",
            "default": 10,
            "min": 1,
            "max": 1000,
            "scope": "algorithm"
        },
        {
            "name": "max_input_length",
            "type": "int",
            "default": -1,
            "min": -1,
            "scope": "algorithm"
        },
        {
            "name": "validation_split_ratio",
            "type": "float",
            "default": 0.2,
            "min": 0,
            "max": 1,
            "scope": "algorithm"
        },
        {
            "name": "train_data_split_seed",
            "type": "int",
            "default": 0,
            "min": 0,
            "scope": "algorithm"
        },
        {
            "name": "preprocessing_num_workers",
            "type": "text",
            "default": "None",
            "scope": "algorithm"
        },
        {
            "name": "sagemaker_submit_directory",
            "type": "text",
            "default": "/opt/ml/input/data/code/sourcedir.tar.gz",
            "scope": "container"
        },
        {
            "name": "sagemaker_program",
            "type": "text",
            "default": "transfer_learning.py",
            "scope": "container"
        },
        {
            "name": "sagemaker_container_log_level",
            "type": "text",
            "default": "20",
            "scope": "container"
        }
    ],
    "training_script_key": "source-directory-tarballs/training/meta-textgeneration/v1.2.0/sourcedir.tar.gz",
    "training_prepacked_script_key": "source-directory-tarballs/training/meta-textgeneration/prepack/inference-meta-textgeneration/v1.2.0/sourcedir.tar.gz",
    "training_prepacked_script_version": "1.2.0",
    "training_ecr_specs": {
        "framework": "huggingface",
        "framework_version": "2.0.0",
        "py_version": "py310",
        "huggingface_transformers_version": "4.28.1"
    },
    "training_artifact_key": "meta-training/v1.1.0/train-meta-textgeneration-llama-2-7b-f.tar.gz",
    "inference_environment_variables": [
        {
            "name": "SAGEMAKER_PROGRAM",
            "type": "text",
            "default": "inference.py",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "SAGEMAKER_SUBMIT_DIRECTORY",
            "type": "text",
            "default": "/opt/ml/model/code",
            "scope": "container",
            "required_for_model_class": false
        },
        {
            "name": "SAGEMAKER_CONTAINER_LOG_LEVEL",
            "type": "text",
            "default": "20",
            "scope": "container",
            "required_for_model_class": false
        },
        {
            "name": "SAGEMAKER_MODEL_SERVER_TIMEOUT",
            "type": "text",
            "default": "3600",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "ENDPOINT_SERVER_TIMEOUT",
            "type": "int",
            "default": 3600,
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "MODEL_CACHE_ROOT",
            "type": "text",
            "default": "/opt/ml/model",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "SAGEMAKER_ENV",
            "type": "text",
            "default": "1",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "HF_MODEL_ID",
            "type": "text",
            "default": "/opt/ml/model",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "OPTION_GPU_MEMORY_UTILIZATION",
            "type": "text",
            "default": "0.85",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "SM_NUM_GPUS",
            "type": "text",
            "default": "1",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "MAX_INPUT_LENGTH",
            "type": "text",
            "default": "4095",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "MAX_TOTAL_TOKENS",
            "type": "text",
            "default": "4096",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "MAX_BATCH_PREFILL_TOKENS",
            "type": "text",
            "default": "8192",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "MAX_CONCURRENT_REQUESTS",
            "type": "text",
            "default": "512",
            "scope": "container",
            "required_for_model_class": true
        },
        {
            "name": "SAGEMAKER_MODEL_SERVER_WORKERS",
            "type": "int",
            "default": 1,
            "scope": "container",
            "required_for_model_class": true
        }
    ],
    "metrics": [
        {
            "Name": "huggingface-textgeneration:eval-loss",
            "Regex": "eval_epoch_loss=tensor\\(([0-9\\.]+)"
        },
        {
            "Name": "huggingface-textgeneration:eval-ppl",
            "Regex": "eval_ppl=tensor\\(([0-9\\.]+)"
        },
        {
            "Name": "huggingface-textgeneration:train-loss",
            "Regex": "train_epoch_loss=([0-9\\.]+)"
        }
    ],
    "default_inference_instance_type": "ml.g5.12xlarge",
    "supported_inference_instance_types": [
        "ml.g5.12xlarge",
        "ml.g5.24xlarge",
        "ml.g5.2xlarge",
        "ml.g5.48xlarge",
        "ml.g5.4xlarge",
        "ml.g5.8xlarge",
        "ml.g6.12xlarge",
        "ml.p4d.24xlarge"
    ],
    "default_training_instance_type": "ml.g5.12xlarge",
    "supported_training_instance_types": [
        "ml.g5.12xlarge",
        "ml.g5.24xlarge",
        "ml.g5.48xlarge",
        "ml.p3dn.24xlarge",
        "ml.g4dn.12xlarge"
    ],
    "model_kwargs": {},
    "estimator_kwargs": {
        "encrypt_inter_container_traffic": true,
        "disable_output_compression": true,
        "max_run": 360000
    },
    "fit_kwargs": {},
    "inference_volume_size": 256,
    "training_volume_size": 256,
    "inference_enable_network_isolation": true,
    "training_enable_network_isolation": true,
    "default_training_dataset_key": "training-datasets/oasst_top/train/",
    "validation_supported": true,
    "fine_tuning_supported": true,
    "resource_name_base": "meta-textgeneration-llama-2-7b-f",
    "gated_bucket": true,
    "training_instance_type_variants": {
        "regional_aliases": {
            "af-south-1": {
                "gpu_ecr_uri_1": "626614931356.dkr.ecr.af-south-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-east-1": {
                "gpu_ecr_uri_1": "871362719292.dkr.ecr.ap-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-northeast-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-northeast-2": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-northeast-3": {
                "gpu_ecr_uri_1": "364406365360.dkr.ecr.ap-northeast-3.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-south-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-southeast-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-southeast-2": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ap-southeast-3": {
                "gpu_ecr_uri_1": "907027046896.dkr.ecr.ap-southeast-3.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ca-central-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.ca-central-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "ca-west-1": {
                "gpu_ecr_uri_1": "204538143572.dkr.ecr.ca-west-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "cn-north-1": {
                "gpu_ecr_uri_1": "727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "cn-northwest-1": {
                "gpu_ecr_uri_1": "727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "eu-central-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-central-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "eu-north-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-north-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "eu-south-1": {
                "gpu_ecr_uri_1": "692866216735.dkr.ecr.eu-south-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "eu-west-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "eu-west-2": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "eu-west-3": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-west-3.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "il-central-1": {
                "gpu_ecr_uri_1": "780543022126.dkr.ecr.il-central-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "me-central-1": {
                "gpu_ecr_uri_1": "914824155844.dkr.ecr.me-central-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "me-south-1": {
                "gpu_ecr_uri_1": "217643126080.dkr.ecr.me-south-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "sa-east-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.sa-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "us-east-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "us-east-2": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "us-gov-east-1": {
                "gpu_ecr_uri_1": "446045086412.dkr.ecr.us-gov-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "us-gov-west-1": {
                "gpu_ecr_uri_1": "442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "us-west-1": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-west-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            },
            "us-west-2": {
                "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04"
            }
        },
        "variants": {
            "g4dn": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                },
                "properties": {
                    "gated_model_key_env_var_value": "meta-training/g4dn/v1.0.0/train-meta-textgeneration-llama-2-7b-f.tar.gz"
                }
            },
            "g5": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                },
                "properties": {
                    "gated_model_key_env_var_value": "meta-training/g5/v1.0.0/train-meta-textgeneration-llama-2-7b-f.tar.gz"
                }
            },
            "g6": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "g6e": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "local_gpu": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p2": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p3": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p3dn": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                },
                "properties": {
                    "gated_model_key_env_var_value": "meta-training/p3dn/v1.0.0/train-meta-textgeneration-llama-2-7b-f.tar.gz"
                }
            },
            "p4d": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p4de": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p5": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p5e": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p5en": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p6": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            },
            "p6e": {
                "regional_properties": {
                    "image_uri": "$gpu_ecr_uri_1"
                }
            }
        }
    },
    "hosting_artifact_s3_data_type": "S3Prefix",
    "hosting_artifact_compression_type": "None",
    "dynamic_container_deployment_supported": true,
    "inference_configs": {
        "tgi": {
            "component_names": [
                "tgi"
            ]
        },
        "lmi": {
            "component_names": [
                "lmi"
            ],
            "benchmark_metrics": {
                "ml.g6.12xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.19",
                        "concurrency": "16"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "19.7",
                        "concurrency": "16"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.22",
                        "concurrency": "32"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "11.6",
                        "concurrency": "32"
                    }
                ],
                "ml.p4d.24xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "2.58",
                        "concurrency": "256"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "3448.3",
                        "concurrency": "256"
                    }
                ]
            }
        },
        "lmi-optimized": {
            "component_names": [
                "lmi-optimized"
            ],
            "benchmark_metrics": {
                "ml.g5.12xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.23",
                        "concurrency": "1"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "156.2",
                        "concurrency": "1"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.25",
                        "concurrency": "2"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "93.1",
                        "concurrency": "2"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.27",
                        "concurrency": "4"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "58.2",
                        "concurrency": "4"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.29",
                        "concurrency": "8"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "31.0",
                        "concurrency": "8"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.42",
                        "concurrency": "16"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "15.2",
                        "concurrency": "16"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.58",
                        "concurrency": "32"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "8.0",
                        "concurrency": "32"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "2.42",
                        "concurrency": "128"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "4.6",
                        "concurrency": "128"
                    }
                ],
                "ml.g5.2xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.19",
                        "concurrency": "1"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "66.9",
                        "concurrency": "1"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.19",
                        "concurrency": "2"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "55.5",
                        "concurrency": "2"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.22",
                        "concurrency": "4"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "41.8",
                        "concurrency": "4"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.44",
                        "concurrency": "8"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "31.3",
                        "concurrency": "8"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "2.87",
                        "concurrency": "16"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "71.1",
                        "concurrency": "16"
                    }
                ],
                "ml.g6.12xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.16",
                        "concurrency": "1"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "107.1",
                        "concurrency": "1"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.17",
                        "concurrency": "2"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "79.5",
                        "concurrency": "2"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.19",
                        "concurrency": "4"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "55.1",
                        "concurrency": "4"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.21",
                        "concurrency": "8"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "34.4",
                        "concurrency": "8"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "3.75",
                        "concurrency": "64"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "8.3",
                        "concurrency": "64"
                    }
                ],
                "ml.g6.2xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.23",
                        "concurrency": "1"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "38.2",
                        "concurrency": "1"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.30",
                        "concurrency": "2"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "32.9",
                        "concurrency": "2"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.30",
                        "concurrency": "4"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "24.5",
                        "concurrency": "4"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.60",
                        "concurrency": "8"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "21.0",
                        "concurrency": "8"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "4.19",
                        "concurrency": "16"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "50.0",
                        "concurrency": "16"
                    }
                ],
                "ml.p4d.24xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.06",
                        "concurrency": "1"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "150.2",
                        "concurrency": "1"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.06",
                        "concurrency": "2"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "149.0",
                        "concurrency": "2"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.06",
                        "concurrency": "4"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "149.0",
                        "concurrency": "4"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.06",
                        "concurrency": "8"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "141.0",
                        "concurrency": "8"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.06",
                        "concurrency": "16"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "128.9",
                        "concurrency": "16"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.06",
                        "concurrency": "32"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "105.2",
                        "concurrency": "32"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.07",
                        "concurrency": "64"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "73.9",
                        "concurrency": "64"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.37",
                        "concurrency": "128"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "68.4",
                        "concurrency": "128"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "4.58",
                        "concurrency": "512"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "11111.1",
                        "concurrency": "512"
                    }
                ],
                "ml.p5.48xlarge": [
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.04",
                        "concurrency": "1"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "253.2",
                        "concurrency": "1"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.03",
                        "concurrency": "2"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "257.1",
                        "concurrency": "2"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.03",
                        "concurrency": "4"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "252.5",
                        "concurrency": "4"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.03",
                        "concurrency": "8"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "236.4",
                        "concurrency": "8"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.04",
                        "concurrency": "16"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "213.2",
                        "concurrency": "16"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.04",
                        "concurrency": "32"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "178.6",
                        "concurrency": "32"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.04",
                        "concurrency": "64"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "129.0",
                        "concurrency": "64"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.04",
                        "concurrency": "128"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "81.2",
                        "concurrency": "128"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "0.33",
                        "concurrency": "256"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "74.5",
                        "concurrency": "256"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "1.77",
                        "concurrency": "512"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "724.6",
                        "concurrency": "512"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "2.96",
                        "concurrency": "768"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "6666.7",
                        "concurrency": "768"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "2.22",
                        "concurrency": "1024"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "5882.4",
                        "concurrency": "1024"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "3.88",
                        "concurrency": "1280"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "11111.1",
                        "concurrency": "1280"
                    },
                    {
                        "name": "latency",
                        "unit": "sec",
                        "value": "3.99",
                        "concurrency": "1536"
                    },
                    {
                        "name": "throughput",
                        "unit": "tokens/sec",
                        "value": "11111.1",
                        "concurrency": "1536"
                    }
                ]
            },
            "acceleration_configs": [
                {
                    "type": "Compilation",
                    "enabled": false
                },
                {
                    "type": "Speculative-Decoding",
                    "enabled": true
                },
                {
                    "type": "Quantization",
                    "enabled": false
                }
            ]
        },
        "neuron": {
            "component_names": [
                "neuron"
            ]
        }
    },
    "inference_config_components": {
        "tgi": {
            "hosting_ecr_specs": {
                "framework": "huggingface-llm",
                "framework_version": "2.0.0",
                "py_version": "py310"
            },
            "hosting_script_key": "source-directory-tarballs/meta/inference/textgeneration/v1.2.3/sourcedir.tar.gz",
            "hosting_use_script_uri": false,
            "inference_dependencies": [],
            "inference_vulnerable": false,
            "inference_vulnerabilities": [],
            "hosting_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference/v1.1.0/",
            "hosting_prepacked_artifact_version": "1.1.0",
            "hosting_prepacked_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference-prepack/v1.1.0/",
            "hosting_artifact_s3_data_type": "S3Prefix",
            "hosting_artifact_compression_type": "None",
            "hosting_neuron_model_id": "meta-textgenerationneuron-llama-2-7b-f",
            "hosting_neuron_model_version": "1.0.0",
            "model_kwargs": {},
            "deploy_kwargs": {
                "model_data_download_timeout": 1200,
                "container_startup_health_check_timeout": 1200
            },
            "predictor_specs": {
                "supported_content_types": [
                    "application/json"
                ],
                "supported_accept_types": [
                    "application/json"
                ],
                "default_content_type": "application/json",
                "default_accept_type": "application/json"
            },
            "default_inference_instance_type": "ml.g5.12xlarge",
            "supported_inference_instance_types": [
                "ml.g5.12xlarge",
                "ml.g5.24xlarge",
                "ml.g5.2xlarge",
                "ml.g5.48xlarge",
                "ml.g5.4xlarge",
                "ml.g5.8xlarge",
                "ml.g6.12xlarge",
                "ml.p4d.24xlarge"
            ],
            "hosting_instance_type_variants": {
                "regional_aliases": {
                    "af-south-1": {
                        "gpu_ecr_uri_1": "626614931356.dkr.ecr.af-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-east-1": {
                        "gpu_ecr_uri_1": "871362719292.dkr.ecr.ap-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-east-2": {
                        "gpu_ecr_uri_1": "975050140332.dkr.ecr.ap-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-northeast-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-northeast-2": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-northeast-3": {
                        "gpu_ecr_uri_1": "364406365360.dkr.ecr.ap-northeast-3.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-south-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-south-2": {
                        "gpu_ecr_uri_1": "772153158452.dkr.ecr.ap-south-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-southeast-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-southeast-2": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-southeast-3": {
                        "gpu_ecr_uri_1": "907027046896.dkr.ecr.ap-southeast-3.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-southeast-4": {
                        "gpu_ecr_uri_1": "457447274322.dkr.ecr.ap-southeast-4.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-southeast-5": {
                        "gpu_ecr_uri_1": "550225433462.dkr.ecr.ap-southeast-5.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ap-southeast-7": {
                        "gpu_ecr_uri_1": "590183813437.dkr.ecr.ap-southeast-7.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ca-central-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.ca-central-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "ca-west-1": {
                        "gpu_ecr_uri_1": "204538143572.dkr.ecr.ca-west-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "cn-north-1": {
                        "gpu_ecr_uri_1": "727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "cn-northwest-1": {
                        "gpu_ecr_uri_1": "727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-central-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-central-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-central-2": {
                        "gpu_ecr_uri_1": "380420809688.dkr.ecr.eu-central-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-north-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-north-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-south-1": {
                        "gpu_ecr_uri_1": "692866216735.dkr.ecr.eu-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-south-2": {
                        "gpu_ecr_uri_1": "503227376785.dkr.ecr.eu-south-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-west-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-west-2": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "eu-west-3": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.eu-west-3.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "il-central-1": {
                        "gpu_ecr_uri_1": "780543022126.dkr.ecr.il-central-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "me-central-1": {
                        "gpu_ecr_uri_1": "914824155844.dkr.ecr.me-central-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "me-south-1": {
                        "gpu_ecr_uri_1": "217643126080.dkr.ecr.me-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "mx-central-1": {
                        "gpu_ecr_uri_1": "637423239942.dkr.ecr.mx-central-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "sa-east-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.sa-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "us-east-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "us-east-2": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "us-gov-east-1": {
                        "gpu_ecr_uri_1": "446045086412.dkr.ecr.us-gov-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "us-gov-west-1": {
                        "gpu_ecr_uri_1": "442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "us-west-1": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-west-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    },
                    "us-west-2": {
                        "gpu_ecr_uri_1": "763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi2.0.0-gpu-py310-cu121-ubuntu22.04"
                    }
                },
                "variants": {
                    "g4dn": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "g5": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "g6": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "g6e": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "local_gpu": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p2": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p3": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p3dn": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p4d": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p4de": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p5": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p5e": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p5en": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p6": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "p6e": {
                        "regional_properties": {
                            "image_uri": "$gpu_ecr_uri_1"
                        }
                    },
                    "ml.g5.12xlarge": {
                        "properties": {
                            "environment_variables": {
                                "SM_NUM_GPUS": "4",
                                "MAX_BATCH_PREFILL_TOKENS": "16384"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 98304,
                                "num_accelerators": 4
                            }
                        }
                    },
                    "ml.g5.24xlarge": {
                        "properties": {
                            "environment_variables": {
                                "SM_NUM_GPUS": "4"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 196608,
                                "num_accelerators": 4
                            }
                        }
                    },
                    "ml.g5.48xlarge": {
                        "properties": {
                            "environment_variables": {
                                "SM_NUM_GPUS": "8"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 393216,
                                "num_accelerators": 8
                            }
                        }
                    },
                    "ml.p4d.24xlarge": {
                        "properties": {
                            "environment_variables": {
                                "SM_NUM_GPUS": "8",
                                "MAX_BATCH_PREFILL_TOKENS": "16384"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 589824,
                                "num_accelerators": 8
                            }
                        }
                    },
                    "ml.p5.48xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_GPU_MEMORY_UTILIZATION": "0.95"
                            }
                        }
                    },
                    "ml.g5.2xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 16384,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.g5.4xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 32768,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.g5.8xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 65536,
                                "num_accelerators": 1
                            }
                        }
                    }
                }
            },
            "inference_volume_size": 256,
            "inference_enable_network_isolation": true,
            "hosting_resource_requirements": {
                "min_memory_mb": 98304,
                "num_accelerators": 4
            },
            "inference_environment_variables": [
                {
                    "name": "SAGEMAKER_PROGRAM",
                    "type": "text",
                    "default": "inference.py",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_SUBMIT_DIRECTORY",
                    "type": "text",
                    "default": "/opt/ml/model/code",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_CONTAINER_LOG_LEVEL",
                    "type": "text",
                    "default": "20",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_TIMEOUT",
                    "type": "text",
                    "default": "3600",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "ENDPOINT_SERVER_TIMEOUT",
                    "type": "int",
                    "default": 3600,
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MODEL_CACHE_ROOT",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_ENV",
                    "type": "text",
                    "default": "1",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "HF_MODEL_ID",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "OPTION_GPU_MEMORY_UTILIZATION",
                    "type": "text",
                    "default": "0.85",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SM_NUM_GPUS",
                    "type": "text",
                    "default": "1",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MAX_INPUT_LENGTH",
                    "type": "text",
                    "default": "4095",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MAX_TOTAL_TOKENS",
                    "type": "text",
                    "default": "4096",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MAX_BATCH_PREFILL_TOKENS",
                    "type": "text",
                    "default": "8192",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MAX_CONCURRENT_REQUESTS",
                    "type": "text",
                    "default": "512",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_WORKERS",
                    "type": "int",
                    "default": 1,
                    "scope": "container",
                    "required_for_model_class": true
                }
            ],
            "default_payloads": {
                "pingExponentialBackoff": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text",
                        "input_logprobs": "[0].details.prefill[*].logprob"
                    },
                    "body": {
                        "inputs": "import socket\n\ndef ping_exponential_backoff(host: str):",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.2,
                            "decoder_input_details": true,
                            "details": true
                        }
                    }
                },
                "argparse": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text"
                    },
                    "body": {
                        "inputs": "import argparse\n\ndef main(string: str):\n    print(string)\n    print(string[::-1])\n\nif __name__ == \"__main__\":",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05
                        }
                    }
                },
                "Fibonacci": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text",
                        "input_logprobs": "[0].details.prefill[*].logprob"
                    },
                    "body": {
                        "inputs": "def fib(n):\n",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.2,
                            "decoder_input_details": true,
                            "details": true
                        }
                    }
                },
                "removeNonAscii": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text",
                        "input_logprobs": "[0].details.prefill[*].logprob"
                    },
                    "body": {
                        "inputs": "def remove_non_ascii(s: str) -> str:\n    \"\"\"<FILL>\n    return result\n",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05,
                            "decoder_input_details": true,
                            "details": true
                        }
                    }
                },
                "installationInstructions": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text"
                    },
                    "body": {
                        "inputs": "# Installation instructions:\n    ```bash\n<FILL>\n    ```\nThis downloads the LLaMA inference code and installs the repository as a local pip package.\n",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05
                        }
                    }
                },
                "interfaceManager": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text"
                    },
                    "body": {
                        "inputs": "class InterfaceManagerFactory(AbstractManagerFactory):\n    def __init__(<FILL>\ndef main():\n    factory = InterfaceManagerFactory(start=datetime.now())\n    managers = []\n    for i in range(10):\n        managers.append(factory.build(id=i))\n",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05
                        }
                    }
                },
                "quasiPrefunctoid": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text"
                    },
                    "body": {
                        "inputs": "/-- A quasi-prefunctoid is 1-connected iff all its etalisations are 1-connected. -/\ntheorem connected_iff_etalisation [C D : precategoroid] (P : quasi_prefunctoid C D) :\n  π₁ P = 0 ↔ <FILL> = 0 :=\nbegin\n  split,\n  { intros h f,\n    rw pi_1_etalisation at h,\n    simp [h],\n    refl\n  },\n  { intro h,\n    have := @quasi_adjoint C D P,\n    simp [←pi_1_etalisation, this, h],\n    refl\n  }\nend\n",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05
                        }
                    }
                },
                "bashListTextFiles": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text",
                        "input_logprobs": "[0].details.prefill[*].logprob"
                    },
                    "body": {
                        "inputs": "<s>[INST] In Bash, how do I list all text files in the current directory (excluding subdirectories) that have been modified in the last month? [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05,
                            "decoder_input_details": true,
                            "details": true
                        }
                    }
                },
                "inorderPreorderTraversal": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text"
                    },
                    "body": {
                        "inputs": "<s>[INST] What is the difference between inorder and preorder traversal? Give an example in Python. [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05
                        }
                    }
                },
                "contiguousSublists": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "[0].generated_text"
                    },
                    "body": {
                        "inputs": "<s>[INST] <<SYS>>\nProvide answers in JavaScript\n<</SYS>>\n\nWrite a function that computes the set of sums of all contiguous sublists of a given list. [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.05
                        }
                    }
                }
            }
        },
        "lmi": {
            "hosting_ecr_specs": {
                "framework": "djl-deepspeed",
                "framework_version": "0.27.0",
                "py_version": "py310"
            },
            "hosting_script_key": "source-directory-tarballs/meta/inference/textgeneration/v1.2.3/sourcedir.tar.gz",
            "hosting_use_script_uri": false,
            "inference_dependencies": [],
            "inference_vulnerable": false,
            "inference_vulnerabilities": [],
            "hosting_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference/v1.1.0/",
            "hosting_prepacked_artifact_version": "1.1.0",
            "hosting_prepacked_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference-prepack/v1.1.0/",
            "hosting_artifact_s3_data_type": "S3Prefix",
            "hosting_artifact_compression_type": "None",
            "hosting_neuron_model_id": "meta-textgenerationneuron-llama-2-7b-f",
            "hosting_neuron_model_version": "1.0.0",
            "model_kwargs": {},
            "deploy_kwargs": {
                "model_data_download_timeout": 1200,
                "container_startup_health_check_timeout": 1200
            },
            "predictor_specs": {
                "supported_content_types": [
                    "application/json"
                ],
                "supported_accept_types": [
                    "application/json"
                ],
                "default_content_type": "application/json",
                "default_accept_type": "application/json"
            },
            "default_inference_instance_type": "ml.g5.12xlarge",
            "supported_inference_instance_types": [
                "ml.g5.12xlarge",
                "ml.g5.24xlarge",
                "ml.g5.2xlarge",
                "ml.g5.48xlarge",
                "ml.g5.4xlarge",
                "ml.g5.8xlarge",
                "ml.g6.12xlarge",
                "ml.p4d.24xlarge"
            ],
            "hosting_instance_type_variants": {
                "regional_aliases": {
                    "af-south-1": {
                        "alias_ecr_uri_1": "626614931356.dkr.ecr.af-south-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-east-1": {
                        "alias_ecr_uri_1": "871362719292.dkr.ecr.ap-east-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-northeast-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-northeast-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-northeast-3": {
                        "alias_ecr_uri_1": "364406365360.dkr.ecr.ap-northeast-3.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-south-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-south-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-southeast-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-southeast-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ap-southeast-3": {
                        "alias_ecr_uri_1": "907027046896.dkr.ecr.ap-southeast-3.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ca-central-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ca-central-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "ca-west-1": {
                        "alias_ecr_uri_1": "204538143572.dkr.ecr.ca-west-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "cn-north-1": {
                        "alias_ecr_uri_1": "727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "cn-northwest-1": {
                        "alias_ecr_uri_1": "727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "eu-central-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-central-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "eu-north-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-north-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "eu-south-1": {
                        "alias_ecr_uri_1": "692866216735.dkr.ecr.eu-south-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "eu-west-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "eu-west-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "eu-west-3": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-3.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "il-central-1": {
                        "alias_ecr_uri_1": "780543022126.dkr.ecr.il-central-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "me-south-1": {
                        "alias_ecr_uri_1": "217643126080.dkr.ecr.me-south-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "sa-east-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.sa-east-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "us-east-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "us-east-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-east-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "us-gov-east-1": {
                        "alias_ecr_uri_1": "446045086412.dkr.ecr.us-gov-east-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "us-gov-west-1": {
                        "alias_ecr_uri_1": "442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "us-west-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-west-1.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    },
                    "us-west-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121"
                    }
                },
                "variants": {
                    "g4dn": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "g5": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "g6": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "g6e": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "local_gpu": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p2": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p3": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p3dn": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p4d": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p4de": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p5": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p5e": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p5en": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p6": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p6e": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "ml.p4d.24xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "1"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 589824,
                                "num_accelerators": 8
                            }
                        }
                    },
                    "ml.p5.48xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "1",
                                "OPTION_GPU_MEMORY_UTILIZATION": "0.95"
                            }
                        }
                    },
                    "ml.g5.2xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 16384,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.g5.4xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 32768,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.g5.8xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 65536,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.g5.12xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 98304,
                                "num_accelerators": 4
                            }
                        }
                    },
                    "ml.g5.24xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 196608,
                                "num_accelerators": 4
                            }
                        }
                    },
                    "ml.g5.48xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 393216,
                                "num_accelerators": 8
                            }
                        }
                    }
                }
            },
            "inference_volume_size": 256,
            "inference_enable_network_isolation": true,
            "hosting_resource_requirements": {
                "min_memory_mb": 98304,
                "num_accelerators": 4
            },
            "inference_environment_variables": [
                {
                    "name": "SAGEMAKER_PROGRAM",
                    "type": "text",
                    "default": "inference.py",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_SUBMIT_DIRECTORY",
                    "type": "text",
                    "default": "/opt/ml/model/code",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_CONTAINER_LOG_LEVEL",
                    "type": "text",
                    "default": "20",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_TIMEOUT",
                    "type": "text",
                    "default": "3600",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "ENDPOINT_SERVER_TIMEOUT",
                    "type": "int",
                    "default": 3600,
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MODEL_CACHE_ROOT",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_ENV",
                    "type": "text",
                    "default": "1",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "HF_MODEL_ID",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "OPTION_GPU_MEMORY_UTILIZATION",
                    "type": "text",
                    "default": "0.85",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_WORKERS",
                    "type": "int",
                    "default": 1,
                    "scope": "container",
                    "required_for_model_class": true
                }
            ],
            "default_payloads": {
                "meaningOfLife": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "I believe the meaning of life is",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6,
                            "decoder_input_details": true,
                            "details": true
                        }
                    }
                },
                "theoryOfRelativity": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "Simply put, the theory of relativity states that ",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "teamMessage": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "A brief message congratulating the team on the launch:\n\nHi everyone,\n\nI just ",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "englishToFrench": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "Translate English to French:\nsea otter => loutre de mer\npeppermint => menthe poivrée\nplush girafe => girafe peluche\ncheese =>",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                }
            }
        },
        "lmi-optimized": {
            "hosting_ecr_specs": {
                "framework": "djl-lmi",
                "framework_version": "0.28.0",
                "py_version": "py310"
            },
            "hosting_script_key": "source-directory-tarballs/meta/inference/textgeneration/v1.2.3/sourcedir.tar.gz",
            "hosting_use_script_uri": false,
            "inference_dependencies": [],
            "inference_vulnerable": false,
            "inference_vulnerabilities": [],
            "hosting_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference/v1.1.0/",
            "hosting_prepacked_artifact_version": "1.1.0",
            "hosting_prepacked_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/inference-prepack/v1.1.0/",
            "hosting_artifact_s3_data_type": "S3Prefix",
            "hosting_artifact_compression_type": "None",
            "hosting_additional_data_sources": {
                "speculative_decoding": [
                    {
                        "channel_name": "draft_model",
                        "artifact_version": "v2",
                        "s3_data_source": {
                            "compression_type": "None",
                            "s3_data_type": "S3Prefix",
                            "s3_uri": "sagemaker-speculative-decoding-llama2-tiny-v2/"
                        }
                    }
                ]
            },
            "hosting_neuron_model_id": "meta-textgenerationneuron-llama-2-7b-f",
            "hosting_neuron_model_version": "1.0.0",
            "model_kwargs": {},
            "deploy_kwargs": {
                "model_data_download_timeout": 1200,
                "container_startup_health_check_timeout": 1200
            },
            "predictor_specs": {
                "supported_content_types": [
                    "application/json"
                ],
                "supported_accept_types": [
                    "application/json"
                ],
                "default_content_type": "application/json",
                "default_accept_type": "application/json"
            },
            "default_inference_instance_type": "ml.p4d.24xlarge",
            "supported_inference_instance_types": [
                "ml.g5.12xlarge",
                "ml.g5.2xlarge",
                "ml.g6.12xlarge",
                "ml.g6.2xlarge",
                "ml.p4d.24xlarge",
                "ml.p4de.24xlarge",
                "ml.p5.48xlarge"
            ],
            "hosting_instance_type_variants": {
                "regional_aliases": {
                    "af-south-1": {
                        "alias_ecr_uri_1": "626614931356.dkr.ecr.af-south-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-east-1": {
                        "alias_ecr_uri_1": "871362719292.dkr.ecr.ap-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-northeast-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-northeast-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-2.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-northeast-3": {
                        "alias_ecr_uri_1": "364406365360.dkr.ecr.ap-northeast-3.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-south-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-south-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-southeast-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-southeast-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-2.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ap-southeast-3": {
                        "alias_ecr_uri_1": "907027046896.dkr.ecr.ap-southeast-3.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ca-central-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ca-central-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "ca-west-1": {
                        "alias_ecr_uri_1": "204538143572.dkr.ecr.ca-west-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "cn-north-1": {
                        "alias_ecr_uri_1": "727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "cn-northwest-1": {
                        "alias_ecr_uri_1": "727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "eu-central-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-central-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "eu-north-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-north-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "eu-south-1": {
                        "alias_ecr_uri_1": "692866216735.dkr.ecr.eu-south-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "eu-west-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "eu-west-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-2.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "eu-west-3": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-3.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "il-central-1": {
                        "alias_ecr_uri_1": "780543022126.dkr.ecr.il-central-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "me-central-1": {
                        "alias_ecr_uri_1": "914824155844.dkr.ecr.me-central-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "me-south-1": {
                        "alias_ecr_uri_1": "217643126080.dkr.ecr.me-south-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "sa-east-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.sa-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "us-east-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "us-east-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-east-2.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "us-gov-east-1": {
                        "alias_ecr_uri_1": "446045086412.dkr.ecr.us-gov-east-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "us-gov-west-1": {
                        "alias_ecr_uri_1": "442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "us-west-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-west-1.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    },
                    "us-west-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.28.0-lmi10.0.0-cu124"
                    }
                },
                "variants": {
                    "g4dn": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "g5": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "g6": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "g6e": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "local_gpu": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p2": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p3": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p3dn": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p4d": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p4de": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p5": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p5e": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p5en": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p6": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "p6e": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "ml.p4d.24xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "1"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 589824,
                                "num_accelerators": 8
                            }
                        }
                    },
                    "ml.p5.48xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "1",
                                "OPTION_GPU_MEMORY_UTILIZATION": "0.95"
                            }
                        }
                    },
                    "ml.p4de.24xlarge": {
                        "properties": {
                            "resource_requirements": {
                                "min_memory_mb": 589824,
                                "num_accelerators": 8
                            }
                        }
                    }
                }
            },
            "inference_volume_size": 256,
            "inference_enable_network_isolation": true,
            "hosting_resource_requirements": {
                "min_memory_mb": 589824,
                "num_accelerators": 8
            },
            "inference_environment_variables": [
                {
                    "name": "SAGEMAKER_PROGRAM",
                    "type": "text",
                    "default": "inference.py",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_SUBMIT_DIRECTORY",
                    "type": "text",
                    "default": "/opt/ml/model/code",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_CONTAINER_LOG_LEVEL",
                    "type": "text",
                    "default": "20",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_TIMEOUT",
                    "type": "text",
                    "default": "3600",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "ENDPOINT_SERVER_TIMEOUT",
                    "type": "int",
                    "default": 3600,
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MODEL_CACHE_ROOT",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_ENV",
                    "type": "text",
                    "default": "1",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "HF_MODEL_ID",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "OPTION_SPECULATIVE_DRAFT_MODEL",
                    "type": "text",
                    "default": "/opt/ml/additional-model-data-sources/draft_model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "OPTION_GPU_MEMORY_UTILIZATION",
                    "type": "text",
                    "default": "0.85",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_WORKERS",
                    "type": "int",
                    "default": 1,
                    "scope": "container",
                    "required_for_model_class": true
                }
            ],
            "default_payloads": {
                "meaningOfLife": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "I believe the meaning of life is",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "theoryOfRelativity": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "Simply put, the theory of relativity states that ",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "teamMessage": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "A brief message congratulating the team on the launch:\n\nHi everyone,\n\nI just ",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "englishToFrench": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "Translate English to French:\nsea otter => loutre de mer\npeppermint => menthe poivrée\nplush girafe => girafe peluche\ncheese =>",
                        "parameters": {
                            "max_new_tokens": 64,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                }
            }
        },
        "neuron": {
            "hosting_ecr_specs": {
                "framework": "djl-neuronx",
                "framework_version": "0.24.0",
                "py_version": "py39"
            },
            "hosting_script_key": "source-directory-tarballs/meta/inference/textgenerationneuron/v1.0.0/sourcedir.tar.gz",
            "hosting_use_script_uri": false,
            "inference_dependencies": [
                "sagemaker_jumpstart_huggingface_script_utilities==1.0.8",
                "sagemaker_jumpstart_script_utilities==1.1.8"
            ],
            "inference_vulnerable": false,
            "inference_vulnerabilities": [],
            "hosting_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/neuron/inference/v1.0.0/",
            "hosting_prepacked_artifact_version": "1.0.0",
            "hosting_prepacked_artifact_key": "meta-textgeneration/meta-textgeneration-llama-2-7b-f/artifacts/neuron/inference-prepack/v1.0.0/",
            "hosting_artifact_s3_data_type": "S3Prefix",
            "hosting_artifact_compression_type": "None",
            "hosting_neuron_model_id": "meta-textgeneration-llama-2-7b-f",
            "hosting_neuron_model_version": "1.0.0",
            "model_kwargs": {},
            "deploy_kwargs": {
                "model_data_download_timeout": 3600,
                "container_startup_health_check_timeout": 3600
            },
            "predictor_specs": {
                "supported_content_types": [
                    "application/json"
                ],
                "supported_accept_types": [
                    "application/json"
                ],
                "default_content_type": "application/json",
                "default_accept_type": "application/json"
            },
            "default_inference_instance_type": "ml.inf2.xlarge",
            "supported_inference_instance_types": [
                "ml.inf2.xlarge",
                "ml.inf2.8xlarge",
                "ml.inf2.24xlarge",
                "ml.inf2.48xlarge"
            ],
            "hosting_instance_type_variants": {
                "regional_aliases": {
                    "ap-northeast-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-northeast-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "ap-south-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-south-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "ap-southeast-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "ap-southeast-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.ap-southeast-2.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "ap-southeast-5": {
                        "alias_ecr_uri_1": "550225433462.dkr.ecr.ap-southeast-5.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "ap-southeast-7": {
                        "alias_ecr_uri_1": "590183813437.dkr.ecr.ap-southeast-7.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "ca-west-1": {
                        "alias_ecr_uri_1": "204538143572.dkr.ecr.ca-west-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "eu-central-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-central-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "eu-central-2": {
                        "alias_ecr_uri_1": "380420809688.dkr.ecr.eu-central-2.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "eu-west-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "eu-west-3": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.eu-west-3.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "mx-central-1": {
                        "alias_ecr_uri_1": "637423239942.dkr.ecr.mx-central-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "sa-east-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.sa-east-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "us-east-1": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "us-east-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-east-2.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    },
                    "us-west-2": {
                        "alias_ecr_uri_1": "763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.24.0-neuronx-sdk2.14.1"
                    }
                },
                "variants": {
                    "inf2": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "trn1": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "trn1n": {
                        "regional_properties": {
                            "image_uri": "$alias_ecr_uri_1"
                        }
                    },
                    "ml.inf2.xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "2",
                                "OPTION_N_POSITIONS": "1024",
                                "OPTION_DTYPE": "fp16",
                                "OPTION_ROLLING_BATCH": "auto",
                                "OPTION_MAX_ROLLING_BATCH_SIZE": "1",
                                "OPTION_NEURON_OPTIMIZE_LEVEL": "2"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 8192,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.inf2.8xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "2",
                                "OPTION_N_POSITIONS": "2048",
                                "OPTION_DTYPE": "fp16",
                                "OPTION_ROLLING_BATCH": "auto",
                                "OPTION_MAX_ROLLING_BATCH_SIZE": "4",
                                "OPTION_NEURON_OPTIMIZE_LEVEL": "2"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 65536,
                                "num_accelerators": 1
                            }
                        }
                    },
                    "ml.inf2.24xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "12",
                                "OPTION_N_POSITIONS": "4096",
                                "OPTION_DTYPE": "fp16",
                                "OPTION_ROLLING_BATCH": "auto",
                                "OPTION_MAX_ROLLING_BATCH_SIZE": "4",
                                "OPTION_NEURON_OPTIMIZE_LEVEL": "2"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 196608,
                                "num_accelerators": 6
                            }
                        }
                    },
                    "ml.inf2.48xlarge": {
                        "properties": {
                            "environment_variables": {
                                "OPTION_TENSOR_PARALLEL_DEGREE": "24",
                                "OPTION_N_POSITIONS": "4096",
                                "OPTION_DTYPE": "fp16",
                                "OPTION_ROLLING_BATCH": "auto",
                                "OPTION_MAX_ROLLING_BATCH_SIZE": "4",
                                "OPTION_NEURON_OPTIMIZE_LEVEL": "2"
                            },
                            "resource_requirements": {
                                "min_memory_mb": 393216,
                                "num_accelerators": 12
                            }
                        }
                    }
                }
            },
            "inference_volume_size": 256,
            "inference_enable_network_isolation": false,
            "hosting_resource_requirements": {
                "min_memory_mb": 8192,
                "num_accelerators": 1
            },
            "inference_environment_variables": [
                {
                    "name": "SAGEMAKER_PROGRAM",
                    "type": "text",
                    "default": "inference.py",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_SUBMIT_DIRECTORY",
                    "type": "text",
                    "default": "/opt/ml/model/code",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_CONTAINER_LOG_LEVEL",
                    "type": "text",
                    "default": "20",
                    "scope": "container",
                    "required_for_model_class": false
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_TIMEOUT",
                    "type": "text",
                    "default": "3600",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "ENDPOINT_SERVER_TIMEOUT",
                    "type": "int",
                    "default": 3600,
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "MODEL_CACHE_ROOT",
                    "type": "text",
                    "default": "/opt/ml/model",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_ENV",
                    "type": "text",
                    "default": "1",
                    "scope": "container",
                    "required_for_model_class": true
                },
                {
                    "name": "SAGEMAKER_MODEL_SERVER_WORKERS",
                    "type": "int",
                    "default": 1,
                    "scope": "container",
                    "required_for_model_class": true
                }
            ],
            "default_payloads": {
                "mayonnaise": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "<s>[INST] what is the recipe of mayonnaise? [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "parisTrip": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "<s>[INST] I am going to Paris, what should I see? [/INST] Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\n\n1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\n2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\n3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\n\nThese are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.</s><s>[INST] What is so great about #1? [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "parisHaiku": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "<s>[INST] <<SYS>>\nAlways answer with Haiku\n<</SYS>>\n\nI am going to Paris, what should I see? [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                },
                "emojisBeijing": {
                    "content_type": "application/json",
                    "prompt_key": "inputs",
                    "output_keys": {
                        "generated_text": "generated_text"
                    },
                    "body": {
                        "inputs": "<s>[INST] <<SYS>>\nAlways answer with detailed instruction\n<</SYS>>\n\nHow to go from Beijing to NY? [/INST] ",
                        "parameters": {
                            "max_new_tokens": 256,
                            "top_p": 0.9,
                            "temperature": 0.6
                        }
                    }
                }
            }
        }
    },
    "inference_config_rankings": {
        "overall": {
            "description": "default",
            "rankings": [
                "tgi",
                "lmi",
                "lmi-optimized",
                "neuron"
            ]
        }
    },
    "hosting_neuron_model_id": "meta-textgenerationneuron-llama-2-7b-f",
    "hosting_neuron_model_version": "1.0.0"
}