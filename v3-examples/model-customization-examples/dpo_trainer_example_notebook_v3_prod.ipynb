{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a96a3ab",
   "metadata": {},
   "source": [
    "# Direct Preference Optimization (DPO) Training with SageMaker\n",
    "\n",
    "This notebook demonstrates how to use the **DPOTrainer** to fine-tune large language models using Direct Preference Optimization (DPO). DPO is a technique that trains models to align with human preferences by learning from preference data without requiring a separate reward model.\n",
    "\n",
    "## What is DPO?\n",
    "\n",
    "Direct Preference Optimization (DPO) is a method for training language models to follow human preferences. Unlike traditional RLHF (Reinforcement Learning from Human Feedback), DPO directly optimizes the model using preference pairs without needing a reward model.\n",
    "\n",
    "**Key Benefits:**\n",
    "- Simpler than RLHF - no reward model required\n",
    "- More stable training process\n",
    "- Direct optimization on preference data\n",
    "- Works with LoRA for efficient fine-tuning\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Prepare Preference Dataset**: Upload preference data in JSONL format\n",
    "2. **Register Dataset**: Create a SageMaker AI Registry dataset\n",
    "3. **Configure DPO Trainer**: Set up model, training parameters, and resources\n",
    "4. **Execute Training**: Run the DPO fine-tuning job\n",
    "5. **Track Results**: Monitor training with MLflow integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446b6a5",
   "metadata": {},
   "source": [
    "## Step 1: Prepare and Register Preference Dataset\n",
    "\n",
    "DPO requires preference data in a specific format where each example contains:\n",
    "- **prompt**: The input text\n",
    "- **chosen**: The preferred response\n",
    "- **rejected**: The less preferred response\n",
    "\n",
    "The dataset should be in JSONL format with each line containing one preference example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d2927f430664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.ai_registry.dataset import DataSet\n",
    "from sagemaker.ai_registry.dataset_utils import CustomizationTechnique\n",
    "\n",
    "\n",
    "# Register dataset in SageMaker AI Registry\n",
    "# This creates a versioned dataset that can be referenced by ARN\n",
    "# Provide a source (it can be local file path or S3 URL)\n",
    "dataset = DataSet.create(\n",
    "    name=\"demo-6\",\n",
    "    source=\"s3://nova-mlflow-us-west-2/dataset/preference_dataset_train_256.jsonl\"\n",
    ")\n",
    "\n",
    "print(f\"Dataset ARN: {dataset.arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28945915-3a40-4a7c-9e7b-7923635780ca",
   "metadata": {},
   "source": [
    "##### Create a Model Package group (if not already exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e3c48-fd53-4304-a09b-a0cc4c1579e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.core.resources import ModelPackage, ModelPackageGroup\n",
    "\n",
    "model_package_group=ModelPackageGroup.create(model_package_group_name=\"test-model-package-group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71071d5c",
   "metadata": {},
   "source": [
    "## Step 2: Configure and Execute DPO Training\n",
    "\n",
    "The **DPOTrainer** provides a high-level interface for DPO fine-tuning with the following key features:\n",
    "\n",
    "### Key Parameters:\n",
    "**Required Parameters** \n",
    "\n",
    "* `model`: base_model id on Sagemaker Hubcontent that is available to finetune (or) ModelPackage artifacts\n",
    "\n",
    "**Optional Parameters**\n",
    "* `training_type`: Choose from TrainingType Enum(sagemaker.modules.train.common) either LORA OR FULL.\n",
    "* `model_package_group`: ModelPackage group name or ModelPackageGroup object. This parameter is mandatory when a base model ID is provided, but optional when a model package is provided.\n",
    "* `mlflow_resource_arn`: MLFlow app ARN to track the training job\n",
    "* `mlflow_experiment_name`: MLFlow app experiment name(str)\n",
    "* `mlflow_run_name`: MLFlow app run name(str)\n",
    "* `training_dataset`: Training Dataset - should be a Dataset ARN or Dataset object (Please note training dataset is required for a training job to run, can be either provided via Trainer or .train())\n",
    "* `validation_dataset`: Validation Dataset - should be a Dataset ARN or Dataset object\n",
    "* `s3_output_path`: S3 path for the trained model artifacts\n",
    "\n",
    "### Training Features:\n",
    "- **Serverless Training**: Automatically managed compute resources\n",
    "- **LoRA Integration**: Parameter-efficient fine-tuning\n",
    "- **MLflow Tracking**: Automatic experiment and metrics logging\n",
    "- **Model Versioning**: Automatic model package creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c280036-b476-43b4-8789-15d9b8be6820",
   "metadata": {},
   "source": [
    "#### Reference \n",
    "Refer this doc for other models that support Model Customization: \n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/custom-model-supported.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42719df1e792227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#! ada credentials update --provider=isengard --account=<> --role=Admin --profile=default --once\n",
    "#! aws configure set region  us-west-2\n",
    "\n",
    "from sagemaker.train.dpo_trainer import DPOTrainer\n",
    "from sagemaker.train.common import TrainingType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352bdaa-fa13-44c5-a70c-0d9bf7a10477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T19:30:51.233369Z",
     "start_time": "2025-12-05T19:30:51.101703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DPOTrainer instance with comprehensive configuration\n",
    "trainer = DPOTrainer(\n",
    "    # Base model from SageMaker Hub\n",
    "    model=\"meta-textgeneration-llama-3-2-1b-instruct\",\n",
    "    \n",
    "    # Use LoRA for efficient fine-tuning\n",
    "    training_type=TrainingType.LORA,\n",
    "    \n",
    "    # Model versioning and storage\n",
    "    model_package_group=model_package_group, # or use an existing model package group arn\n",
    "        \n",
    "    # Training data (from Step 1)\n",
    "    training_dataset=dataset.arn,\n",
    "    \n",
    "    # Output configuration\n",
    "    s3_output_path=\"s3://mc-flows-sdk-testing/output/\",\n",
    "\n",
    "    \n",
    "    # Unique job name\n",
    "    base_job_name=f\"dpo-job-{random.randint(1, 1000)}\",\n",
    "    accept_eula=True\n",
    ")\n",
    "\n",
    "# Customize training hyperparameters\n",
    "# DPO-specific parameters are automatically loaded from the model's recipe\n",
    "trainer.hyperparameters.max_epochs = 1  # Quick training for demo\n",
    "\n",
    "print(\"Starting DPO training job...\")\n",
    "print(f\"Job name: {trainer.base_job_name}\")\n",
    "print(f\"Base model: {trainer._model_name}\")\n",
    "\n",
    "# Execute training with monitoring\n",
    "training_job = trainer.train(wait=True)\n",
    "\n",
    "print(f\"Training completed! Job ARN: {training_job.training_job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6a210-0a0c-4b7a-af4d-2e08eae1c048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.core.utils.utils import Unassigned\n",
    "\n",
    "def pretty_print(obj):\n",
    "    def parse_unassigned(item):\n",
    "        if isinstance(item, Unassigned):\n",
    "            return None\n",
    "        if isinstance(item, dict):\n",
    "            return {k: parse_unassigned(v) for k, v in item.items() if parse_unassigned(v) is not None}\n",
    "        if isinstance(item, list):\n",
    "            return [parse_unassigned(x) for x in item if parse_unassigned(x) is not None]\n",
    "        if isinstance(item, str) and \"Unassigned object\" in item:\n",
    "            pairs = re.findall(r\"(\\w+)=([^<][^=]*?)(?=\\s+\\w+=|$)\", item)\n",
    "            result = {k: v.strip(\"'\\\"\") for k, v in pairs}\n",
    "            return result if result else None\n",
    "        return item\n",
    "\n",
    "    cleaned = parse_unassigned(obj.__dict__ if hasattr(obj, '__dict__') else obj)\n",
    "    print(json.dumps(cleaned, indent=2, default=str))\n",
    "pretty_print(training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b3188-582d-4a3b-9f32-e7f17f962aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the training job object\n",
    "\n",
    "import json\n",
    "from sagemaker.core.utils.utils import Unassigned\n",
    "from sagemaker.core.resources import TrainingJob\n",
    "import pprint\n",
    "response = TrainingJob.get(training_job_name=\"generate-sql-queries-bas-base-judge-y6cfcrah49j7-090dlKtAnQ\")\n",
    "\n",
    "import json\n",
    "import re\n",
    "from sagemaker.core.utils.utils import Unassigned\n",
    "\n",
    "# Usage\n",
    "pretty_print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7545b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After training completes, you can:\n",
    "\n",
    "1. **Deploy the Model**: Use `ModelBuilder` to deploy the fine-tuned model\n",
    "2. **Evaluate Performance**: Compare responses from base vs fine-tuned model\n",
    "3. **Monitor Metrics**: Review training metrics in MLflow\n",
    "4. **Iterate**: Adjust hyperparameters and retrain if needed\n",
    "\n",
    "### Example Deployment:\n",
    "```python\n",
    "from sagemaker.serve import ModelBuilder\n",
    "\n",
    "# Deploy the fine-tuned model\n",
    "model_builder = ModelBuilder(model=training_job)\n",
    "model_builder.build(role_arn=\"arn:aws:iam::account:role/SageMakerRole\")\n",
    "endpoint = model_builder.deploy(endpoint_name=\"dpo-finetuned-llama\")\n",
    "```\n",
    "\n",
    "The fine-tuned model will now generate responses that better align with the preferences in your training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
