{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0d57a8",
   "metadata": {},
   "source": [
    "# Demo: Deploy Models Locally with SageMaker Model Builder in IN_PROCESS Mode\n",
    "\n",
    "This notebook was tested with the `Python 3` kernel on an Amazon SageMaker notebook instance of type `ml.g5.4xlarge`.\n",
    "\n",
    "In this notebook, we demonstrate how customers can deploy a model locally to a FastAPI server without needing to set up a container. This approach enables quicker validation and allows faster iteration before customers proceed with deployment using either local container mode or SageMaker endpoint mode. After successful in-process testing, customers can switch to another mode for further testing.\n",
    "\n",
    "You can either launch this notebook from an Amazon SageMaker notebook instance which handles all credentials automatically, or by running it locally and setting credentials manually.\n",
    "\n",
    "***\n",
    "\n",
    "The notebook is accompanied by the following files:\n",
    "- `sagemaker-2.232.4.dev0-py3-none-any.whl`: The whl file containing all of the PythonSDK changes for these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249dfff4-41cd-4595-8171-3af2b5d7898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a08e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==65.5.1\n",
      "  Downloading setuptools-65.5.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Downloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-65.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.1.1 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "aiobotocore 2.13.3 requires botocore<1.34.163,>=1.34.70, but you have botocore 1.35.62 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.2 which is incompatible.\n",
      "autogluon-common 1.1.1 requires psutil<6,>=5.7.3, but you have psutil 6.1.0 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-core 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-features 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires Pillow<11,>=10.0.1, but you have pillow 11.0.0 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-multimodal 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scikit-learn<1.4.1,>=1.3.0, but you have scikit-learn 1.5.2 which is incompatible.\n",
      "autogluon-tabular 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires gluonts==0.15.1, but you have gluonts 0.14.3 which is incompatible.\n",
      "autogluon-timeseries 1.1.1 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.1 which is incompatible.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.2.3 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "jupyter-scheduler 2.9.0 requires psutil~=5.9, but you have psutil 6.1.0 which is incompatible.\n",
      "jupyter-scheduler 2.9.0 requires pytz==2023.3, but you have pytz 2024.2 which is incompatible.\n",
      "langchain-aws 0.1.18 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.62 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "virtualenv 20.21.0 requires platformdirs<4,>=2.4, but you have platformdirs 4.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall --no-cache-dir --quiet sagemaker-2.232.4.dev0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54defff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyopenssl in /opt/conda/lib/python3.11/site-packages (24.2.1)\n",
      "Requirement already satisfied: cryptography<44,>=41.0.5 in /opt/conda/lib/python3.11/site-packages (from pyopenssl) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography<44,>=41.0.5->pyopenssl) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyopenssl) (2.22)\n"
     ]
    }
   ],
   "source": [
    "# import these to run fast api servers\n",
    "# TO_DO: add these to sagemaker pysdk requirements.\n",
    "!pip install --quiet torch transformers fastapi uvicorn nest-asyncio\n",
    "!pip install -U pyopenssl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b83ba",
   "metadata": {},
   "source": [
    "# [WalkThrough] Define the custom inference code\n",
    "Just tell us how to load your model and how to invoke it. We'll take care of the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e23e5d-c863-4528-a3b8-ec83cd6889e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serve.spec.inference_spec import InferenceSpec\n",
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "\n",
    "class MyInferenceSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        return pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    def invoke(self, input_data, model):\n",
    "        if isinstance(input_data, str):\n",
    "            input_data = json.loads(input_data)\n",
    "        response = model(question=input_data[\"question\"], context=input_data[\"context\"])\n",
    "        return response\n",
    "\n",
    "\n",
    "inf_spec = MyInferenceSpec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a0639-88ca-4aae-94d1-101d63e74501",
   "metadata": {},
   "source": [
    "# [WalkThrough] Start the IN_PROCESS mode server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58184f43-61b4-4299-b873-bc2cf6ff5fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: INFO:     Either inference spec or model is provided. ModelBuilder is not handling MLflow model input\n",
      "ModelBuilder: INFO:     ModelBuilder will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features. To opt out of telemetry, please disable via TelemetryOptOut in intelligent defaults. See https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk for more info.\n",
      "ModelBuilder: INFO:     Waiting for fastapi server to start up...\n",
      "ModelBuilder: WARNING:     Note: This is not a standard model server.\n",
      "ModelBuilder: WARNING:     The model is being hosted directly on the FastAPI server.\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "ModelBuilder: INFO:     Waiting for a connection...\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m1797\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:9007\u001b[0m (Press CTRL+C to quit)\n",
      "ModelBuilder: DEBUG:     Received request: {'context': 'The demo is focused on SageMaker and machine learning. It has gone well so far, with no major issues, and the participants are engaged.', 'question': 'What is the demo about?'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:56262 - \"\u001b[1mPOST /invoke HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: DEBUG:     Ping health check has passed. Returned b'{\"score\":0.7950457334518433,\"start\":23,\"end\":53,\"answer\":\"SageMaker and machine learning\"}'\n",
      "ModelBuilder: DEBUG:     ModelBuilder metrics emitted.\n",
      "ModelBuilder: DEBUG:     Received request: {'question': 'What is the main topic?', 'context': 'The demo is focused on SageMaker and machine learning. It has gone well so far, with no major issues, and the participants are engaged.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:50454 - \"\u001b[1mPOST /invoke HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serve import Mode\n",
    "from sagemaker.serve.builder.model_builder import ModelBuilder\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "\n",
    "# Expected output: the model’s answer based on the provided context\n",
    "schema = SchemaBuilder(\n",
    "    {\n",
    "        \"context\": \"The demo is focused on SageMaker and machine learning. It has gone well so far, with no major issues, and the participants are engaged.\",\n",
    "        \"question\": \"What is the demo about?\"\n",
    "    },\n",
    "    {\n",
    "        \"answer\": \"SageMaker and machine learning.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# deploying the model to a fast api server with minimum inputs from user\n",
    "predictor = ModelBuilder(\n",
    "    inference_spec=inf_spec,\n",
    "    schema_builder=schema,\n",
    "    mode=Mode.IN_PROCESS,  # you can change it to Mode.LOCAL_CONTAINER for local container testing\n",
    ").build().deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bfe83-2e67-4ed7-a697-9ac99ca95360",
   "metadata": {},
   "source": [
    "# [WalkThrough] Now that the server is running, send a prompt and see the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e793be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"score\":0.8696708679199219,\"start\":23,\"end\":53,\"answer\":\"SageMaker and machine learning\"}'\n"
     ]
    }
   ],
   "source": [
    "# Define input data for the question-answering model\n",
    "input_data = {\n",
    "    \"question\": \"What is the main topic?\",\n",
    "    \"context\": \"The demo is focused on SageMaker and machine learning. It has gone well so far, with no major issues, and the participants are engaged.\"\n",
    "}\n",
    "\n",
    "# Convert the input data to JSON format and pass it to `predict`\n",
    "response = predictor.predict(input_data)\n",
    "\n",
    "# Check the model's response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b21f62",
   "metadata": {},
   "source": [
    "## [WalkThrough] Cleanup the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2fd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelBuilder: INFO:     Shutting down the server...\n",
      "ModelBuilder: INFO:     Server shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c073467-4bb7-4719-bebf-718ed6c81bf1",
   "metadata": {},
   "source": [
    "---\n",
    "# Now try it out for yourself\n",
    "\n",
    "Samples:\n",
    "- Can this embedding model to work with IN_PROCESS mode? https://huggingface.co/BAAI/bge-m3#generate-embedding-for-text\n",
    "- Can yo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8665c-9623-4a54-a49d-6a813086636f",
   "metadata": {},
   "source": [
    "# Your custom load and invoke logic here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "795c93ee-2812-436b-8274-8e4119025ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInferenceSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        # your load logic here <---\n",
    "        pass\n",
    "\n",
    "    def invoke(self, input_data, model):\n",
    "        # your invoke logic here <---\n",
    "        pass\n",
    "\n",
    "inf_spec = MyInferenceSpec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73b019-5913-4ae8-93e2-a9aeda9c7db7",
   "metadata": {},
   "source": [
    "# Now deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb0c35-29b7-46b9-bf34-5d809cc87024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serve import Mode\n",
    "from sagemaker.serve.builder.model_builder import ModelBuilder\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "\n",
    "schema = SchemaBuilder(\n",
    "    {},\n",
    "    {}\n",
    ")\n",
    "\n",
    "predictor = ModelBuilder(\n",
    "    inference_spec=inf_spec,\n",
    "    schema_builder=schema,\n",
    "    mode=Mode.IN_PROCESS,\n",
    ").build().deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9103478a-8e22-4ebe-81b1-592933e7188b",
   "metadata": {},
   "source": [
    "# Now invoke it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be1786-d1a9-4461-80ae-6d2122f39011",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {} # your input data here <---\n",
    "\n",
    "response = predictor.predict(input_data)\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

